{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo de Regresión Logistica en Python\n",
    "=======================================\n",
    "\n",
    "En el articulo anterior, creamos un modelo de predicción de enfermedades cardiacas usando un modelo de regresión logistica en RapidMiner. En este articulo, vamos a crear el mismo modelo usando Python.\n",
    "\n",
    "## Carga de datos\n",
    "\n",
    "Utilizaremos el mismo archivo de datos que en el articulo anterior. Este archivo fue creado luego de procesar las cuatro bases de datos originales, conviertiendolas a un formato csv mas fácil de importar a las distintas herramientas de aprendizaje automatizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: pd.DataFrame = pd.read_csv('./datasets/procesados/full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aseguremonos antes de continuar, de que cada columna tenga el tipo de datos correcto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 899 entries, 0 to 898\n",
      "Data columns (total 77 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   dataset   899 non-null    string  \n",
      " 1   id        899 non-null    Int64   \n",
      " 2   ccf       899 non-null    Int64   \n",
      " 3   age       899 non-null    Int64   \n",
      " 4   sex       899 non-null    category\n",
      " 5   painloc   617 non-null    category\n",
      " 6   painexer  617 non-null    category\n",
      " 7   relrest   613 non-null    category\n",
      " 8   pncaden   0 non-null      category\n",
      " 9   cp        899 non-null    category\n",
      " 10  trestbps  840 non-null    float64 \n",
      " 11  htn       865 non-null    object  \n",
      " 12  chol      869 non-null    float64 \n",
      " 13  smoke     230 non-null    category\n",
      " 14  cigs      479 non-null    Int64   \n",
      " 15  years     467 non-null    Int64   \n",
      " 16  fbs       809 non-null    category\n",
      " 17  dm        95 non-null     category\n",
      " 18  famhist   477 non-null    category\n",
      " 19  restecg   897 non-null    category\n",
      " 20  ekgmo     846 non-null    Int64   \n",
      " 21  ekgday    845 non-null    Int64   \n",
      " 22  ekgyr     846 non-null    Int64   \n",
      " 23  dig       831 non-null    category\n",
      " 24  prop      833 non-null    category\n",
      " 25  nitr      834 non-null    category\n",
      " 26  pro       836 non-null    category\n",
      " 27  diuretic  817 non-null    category\n",
      " 28  proto     787 non-null    category\n",
      " 29  thaldur   843 non-null    float64 \n",
      " 30  thaltime  446 non-null    float64 \n",
      " 31  met       794 non-null    float64 \n",
      " 32  thalach   844 non-null    float64 \n",
      " 33  thalrest  843 non-null    float64 \n",
      " 34  tpeakbps  836 non-null    float64 \n",
      " 35  tpeakbpd  836 non-null    float64 \n",
      " 36  dummy     840 non-null    object  \n",
      " 37  trestbpd  840 non-null    float64 \n",
      " 38  exang     844 non-null    category\n",
      " 39  xhypo     841 non-null    category\n",
      " 40  oldpeak   837 non-null    float64 \n",
      " 41  slope     591 non-null    category\n",
      " 42  rldv5     474 non-null    float64 \n",
      " 43  rldv5e    757 non-null    float64 \n",
      " 44  ca        291 non-null    Int64   \n",
      " 45  restckm   0 non-null      object  \n",
      " 46  exerckm   1 non-null      object  \n",
      " 47  restef    28 non-null     float64 \n",
      " 48  restwm    30 non-null     category\n",
      " 49  exeref    2 non-null      float64 \n",
      " 50  exerwm    5 non-null      float64 \n",
      " 51  thal      422 non-null    category\n",
      " 52  thalsev   130 non-null    object  \n",
      " 53  thalpul   44 non-null     object  \n",
      " 54  earlobe   1 non-null      object  \n",
      " 55  cmo       888 non-null    Int64   \n",
      " 56  cday      890 non-null    Int64   \n",
      " 57  cyr       890 non-null    Int64   \n",
      " 58  num       899 non-null    category\n",
      " 59  lmt       624 non-null    object  \n",
      " 60  ladprox   663 non-null    object  \n",
      " 61  laddist   653 non-null    object  \n",
      " 62  diag      341 non-null    object  \n",
      " 63  cxmain    664 non-null    object  \n",
      " 64  ramus     332 non-null    object  \n",
      " 65  om1       628 non-null    object  \n",
      " 66  om2       327 non-null    object  \n",
      " 67  rcaprox   654 non-null    object  \n",
      " 68  rcadist   629 non-null    object  \n",
      " 69  lvx1      880 non-null    object  \n",
      " 70  lvx2      880 non-null    object  \n",
      " 71  lvx3      880 non-null    object  \n",
      " 72  lvx4      880 non-null    object  \n",
      " 73  lvf       883 non-null    object  \n",
      " 74  cathef    311 non-null    object  \n",
      " 75  junk      119 non-null    object  \n",
      " 76  name      899 non-null    string  \n",
      "dtypes: Int64(12), category(23), float64(16), object(24), string(2)\n",
      "memory usage: 414.0+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    ('id', 'Int64'),\n",
    "    ('ccf', 'Int64'),\n",
    "    ('age', 'Int64'),\n",
    "    ('sex', 'category'),\n",
    "    ('painloc', 'category'),\n",
    "    ('painexer', 'category'),\n",
    "    ('relrest', 'category'),\n",
    "    ('pncaden', 'category'),\n",
    "    ('cp', 'category'),\n",
    "    ('trestbps', 'float'),\n",
    "    ('htn', 'object'),\n",
    "    ('chol', 'float'),\n",
    "    ('smoke', 'category'),\n",
    "    ('cigs', 'Int64'),\n",
    "    ('years', 'Int64'),\n",
    "    ('fbs', 'category'),\n",
    "    ('dm', 'category'),\n",
    "    ('famhist', 'category'),\n",
    "    ('restecg', 'category'),\n",
    "    ('ekgmo', 'Int64'),\n",
    "    ('ekgday', 'Int64'),\n",
    "    ('ekgyr', 'Int64'),\n",
    "    ('dig', 'category'),\n",
    "    ('prop', 'category'),\n",
    "    ('nitr', 'category'),\n",
    "    ('pro', 'category'),\n",
    "    ('diuretic', 'category'),\n",
    "    ('proto', 'category'),\n",
    "    ('thaldur', 'float'),\n",
    "    ('thaltime', 'float'),\n",
    "    ('met', 'float'),\n",
    "    ('thalach', 'float'),\n",
    "    ('thalrest', 'float'),\n",
    "    ('tpeakbps', 'float'),\n",
    "    ('tpeakbpd', 'float'),\n",
    "    ('dummy', 'object'),\n",
    "    ('trestbpd', 'float'),\n",
    "    ('exang', 'category'),\n",
    "    ('xhypo', 'category'),\n",
    "    ('oldpeak', 'float'),\n",
    "    ('slope', 'category'),\n",
    "    ('rldv5', 'float'),\n",
    "    ('rldv5e', 'float'),\n",
    "    ('ca', 'Int64'),\n",
    "    ('restckm', 'object'),\n",
    "    ('exerckm', 'object'),\n",
    "    ('restef', 'float'),\n",
    "    ('restwm', 'category'),\n",
    "    ('exeref', 'float'),\n",
    "    ('exerwm', 'float'),\n",
    "    ('thal', 'category'),\n",
    "    ('thalsev', 'object'),\n",
    "    ('thalpul', 'object'),\n",
    "    ('earlobe', 'object'),\n",
    "    ('cmo', 'Int64'),\n",
    "    ('cday', 'Int64'),\n",
    "    ('cyr', 'Int64'),\n",
    "    ('num', 'category'),\n",
    "    ('lmt', 'object'),\n",
    "    ('ladprox', 'object'),\n",
    "    ('laddist', 'object'),\n",
    "    ('diag', 'object'),\n",
    "    ('cxmain', 'object'),\n",
    "    ('ramus', 'object'),\n",
    "    ('om1', 'object'),\n",
    "    ('om2', 'object'),\n",
    "    ('rcaprox', 'object'),\n",
    "    ('rcadist', 'object'),\n",
    "    ('lvx1', 'object'),\n",
    "    ('lvx2', 'object'),\n",
    "    ('lvx3', 'object'),\n",
    "    ('lvx4', 'object'),\n",
    "    ('lvf', 'object'),\n",
    "    ('cathef', 'object'),\n",
    "    ('junk', 'object'),\n",
    "    ('name', 'string'),\n",
    "    ('dataset', 'string')\n",
    "]\n",
    "\n",
    "dataset = dataset.astype(dict(columns))\n",
    "\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "En el articulo anterior, realizamos un preprocesamiento de los datos usando RapidMiner. En este caso, realizaremos el preprocesamiento usando Python. Para ello, utilizaremos las librerias Pandas y Numpy.\n",
    "\n",
    "Inicialmente, tomaremos la variable objetivo `num` y convertiremos todo valor distinto de cero a 1. Esto es necesario para que el modelo de regresión logistica pueda funcionar correctamente ya que es un modelo de clasificación binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "Categories (2, int64): [0, 1]\n"
     ]
    }
   ],
   "source": [
    "for value in dataset['num'].unique():\n",
    "    if value > 0:\n",
    "        dataset['num'] = dataset['num'].replace(value, 1)\n",
    "\n",
    "print(dataset['num'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, tomemos todas las columnas que contienen una cantidad de valores faltantes mayor a 400 y eliminemos esas columnas del dataset. Este numero fue seleccionado basados en que existen 899 registros en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 899 entries, 0 to 898\n",
      "Data columns (total 53 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   dataset   899 non-null    string  \n",
      " 1   id        899 non-null    Int64   \n",
      " 2   ccf       899 non-null    Int64   \n",
      " 3   age       899 non-null    Int64   \n",
      " 4   sex       899 non-null    category\n",
      " 5   painloc   617 non-null    category\n",
      " 6   painexer  617 non-null    category\n",
      " 7   relrest   613 non-null    category\n",
      " 8   cp        899 non-null    category\n",
      " 9   trestbps  840 non-null    float64 \n",
      " 10  htn       865 non-null    object  \n",
      " 11  chol      869 non-null    float64 \n",
      " 12  fbs       809 non-null    category\n",
      " 13  restecg   897 non-null    category\n",
      " 14  ekgmo     846 non-null    Int64   \n",
      " 15  ekgday    845 non-null    Int64   \n",
      " 16  ekgyr     846 non-null    Int64   \n",
      " 17  dig       831 non-null    category\n",
      " 18  prop      833 non-null    category\n",
      " 19  nitr      834 non-null    category\n",
      " 20  pro       836 non-null    category\n",
      " 21  diuretic  817 non-null    category\n",
      " 22  proto     787 non-null    category\n",
      " 23  thaldur   843 non-null    float64 \n",
      " 24  met       794 non-null    float64 \n",
      " 25  thalach   844 non-null    float64 \n",
      " 26  thalrest  843 non-null    float64 \n",
      " 27  tpeakbps  836 non-null    float64 \n",
      " 28  tpeakbpd  836 non-null    float64 \n",
      " 29  dummy     840 non-null    object  \n",
      " 30  trestbpd  840 non-null    float64 \n",
      " 31  exang     844 non-null    category\n",
      " 32  xhypo     841 non-null    category\n",
      " 33  oldpeak   837 non-null    float64 \n",
      " 34  slope     591 non-null    category\n",
      " 35  rldv5e    757 non-null    float64 \n",
      " 36  cmo       888 non-null    Int64   \n",
      " 37  cday      890 non-null    Int64   \n",
      " 38  cyr       890 non-null    Int64   \n",
      " 39  num       899 non-null    category\n",
      " 40  lmt       624 non-null    object  \n",
      " 41  ladprox   663 non-null    object  \n",
      " 42  laddist   653 non-null    object  \n",
      " 43  cxmain    664 non-null    object  \n",
      " 44  om1       628 non-null    object  \n",
      " 45  rcaprox   654 non-null    object  \n",
      " 46  rcadist   629 non-null    object  \n",
      " 47  lvx1      880 non-null    object  \n",
      " 48  lvx2      880 non-null    object  \n",
      " 49  lvx3      880 non-null    object  \n",
      " 50  lvx4      880 non-null    object  \n",
      " 51  lvf       883 non-null    object  \n",
      " 52  name      899 non-null    string  \n",
      "dtypes: Int64(9), category(17), float64(11), object(14), string(2)\n",
      "memory usage: 278.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "examples_count = dataset.shape[0]\n",
    "dataset = dataset.dropna(axis=1, thresh=examples_count - 400)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora procedemos a eliminar las columnas que son marcadas por el autor del dataset como no relevantes para el modelo. Estas columnas son `ccf`, `dummy`, `lvx1`, `lvx2`, `lvx3`, `lvx4`, `lvf`, `junk`, y `name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 899 entries, 0 to 898\n",
      "Data columns (total 45 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   dataset   899 non-null    string  \n",
      " 1   id        899 non-null    Int64   \n",
      " 2   age       899 non-null    Int64   \n",
      " 3   sex       899 non-null    category\n",
      " 4   painloc   617 non-null    category\n",
      " 5   painexer  617 non-null    category\n",
      " 6   relrest   613 non-null    category\n",
      " 7   cp        899 non-null    category\n",
      " 8   trestbps  840 non-null    float64 \n",
      " 9   htn       865 non-null    object  \n",
      " 10  chol      869 non-null    float64 \n",
      " 11  fbs       809 non-null    category\n",
      " 12  restecg   897 non-null    category\n",
      " 13  ekgmo     846 non-null    Int64   \n",
      " 14  ekgday    845 non-null    Int64   \n",
      " 15  ekgyr     846 non-null    Int64   \n",
      " 16  dig       831 non-null    category\n",
      " 17  prop      833 non-null    category\n",
      " 18  nitr      834 non-null    category\n",
      " 19  pro       836 non-null    category\n",
      " 20  diuretic  817 non-null    category\n",
      " 21  proto     787 non-null    category\n",
      " 22  thaldur   843 non-null    float64 \n",
      " 23  met       794 non-null    float64 \n",
      " 24  thalach   844 non-null    float64 \n",
      " 25  thalrest  843 non-null    float64 \n",
      " 26  tpeakbps  836 non-null    float64 \n",
      " 27  tpeakbpd  836 non-null    float64 \n",
      " 28  trestbpd  840 non-null    float64 \n",
      " 29  exang     844 non-null    category\n",
      " 30  xhypo     841 non-null    category\n",
      " 31  oldpeak   837 non-null    float64 \n",
      " 32  slope     591 non-null    category\n",
      " 33  rldv5e    757 non-null    float64 \n",
      " 34  cmo       888 non-null    Int64   \n",
      " 35  cday      890 non-null    Int64   \n",
      " 36  cyr       890 non-null    Int64   \n",
      " 37  num       899 non-null    category\n",
      " 38  lmt       624 non-null    object  \n",
      " 39  ladprox   663 non-null    object  \n",
      " 40  laddist   653 non-null    object  \n",
      " 41  cxmain    664 non-null    object  \n",
      " 42  om1       628 non-null    object  \n",
      " 43  rcaprox   654 non-null    object  \n",
      " 44  rcadist   629 non-null    object  \n",
      "dtypes: Int64(8), category(17), float64(11), object(8), string(1)\n",
      "memory usage: 221.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "columns = [\n",
    "    'ccf',\n",
    "    'dummy',\n",
    "    'lvx1',\n",
    "    'lvx2',\n",
    "    'lvx3',\n",
    "    'lvx4',\n",
    "    'lvf',\n",
    "    'name'\n",
    "]\n",
    "\n",
    "dataset = dataset.drop(columns, axis=1)\n",
    "# dataset = dataset.select_dtypes(exclude=['object'])\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto nos encontramos con 51 atributos. Dejemos de lado la seleccion de atributos por el momento y continuemos con otras tareas de preprocesamiento.\n",
    "\n",
    "Ahora, tomemos las columnas que contienen valores faltantes y reemplacemos esos valores por el promedio de la columna. En el caso de numeros reales, tomemos el promedio de los valores. En el caso de valores discretos, tomemos el valor mas frecuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reeplazemos valores faltantes de columnas 'float', por la media.\n",
    "for column in dataset.columns:\n",
    "    if dataset[column].dtype == 'float64':\n",
    "        dataset[column] = dataset[column].fillna(dataset[column].mean())\n",
    "\n",
    "# Reemplazamos valores faltantes de columnas 'category', por la moda.\n",
    "for column in dataset.columns:\n",
    "    if dataset[column].dtype == 'category':\n",
    "        dataset[column] = dataset[column].fillna(dataset[column].mode()[0])\n",
    "\n",
    "# Reemplazamos valores faltantes de columnas 'Int64', por la moda.\n",
    "for column in dataset.columns:\n",
    "    if dataset[column].dtype == 'Int64':\n",
    "        dataset[column] = dataset[column].fillna(dataset[column].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya con los valores faltantes que podemos reemplazar, reemplazados, eliminemos las filas que contienen valores faltantes en las columnas restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 572 entries, 0 to 898\n",
      "Data columns (total 45 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   dataset   572 non-null    string  \n",
      " 1   id        572 non-null    Int64   \n",
      " 2   age       572 non-null    Int64   \n",
      " 3   sex       572 non-null    category\n",
      " 4   painloc   572 non-null    category\n",
      " 5   painexer  572 non-null    category\n",
      " 6   relrest   572 non-null    category\n",
      " 7   cp        572 non-null    category\n",
      " 8   trestbps  572 non-null    float64 \n",
      " 9   htn       572 non-null    object  \n",
      " 10  chol      572 non-null    float64 \n",
      " 11  fbs       572 non-null    category\n",
      " 12  restecg   572 non-null    category\n",
      " 13  ekgmo     572 non-null    Int64   \n",
      " 14  ekgday    572 non-null    Int64   \n",
      " 15  ekgyr     572 non-null    Int64   \n",
      " 16  dig       572 non-null    category\n",
      " 17  prop      572 non-null    category\n",
      " 18  nitr      572 non-null    category\n",
      " 19  pro       572 non-null    category\n",
      " 20  diuretic  572 non-null    category\n",
      " 21  proto     572 non-null    category\n",
      " 22  thaldur   572 non-null    float64 \n",
      " 23  met       572 non-null    float64 \n",
      " 24  thalach   572 non-null    float64 \n",
      " 25  thalrest  572 non-null    float64 \n",
      " 26  tpeakbps  572 non-null    float64 \n",
      " 27  tpeakbpd  572 non-null    float64 \n",
      " 28  trestbpd  572 non-null    float64 \n",
      " 29  exang     572 non-null    category\n",
      " 30  xhypo     572 non-null    category\n",
      " 31  oldpeak   572 non-null    float64 \n",
      " 32  slope     572 non-null    category\n",
      " 33  rldv5e    572 non-null    float64 \n",
      " 34  cmo       572 non-null    Int64   \n",
      " 35  cday      572 non-null    Int64   \n",
      " 36  cyr       572 non-null    Int64   \n",
      " 37  num       572 non-null    category\n",
      " 38  lmt       572 non-null    object  \n",
      " 39  ladprox   572 non-null    object  \n",
      " 40  laddist   572 non-null    object  \n",
      " 41  cxmain    572 non-null    object  \n",
      " 42  om1       572 non-null    object  \n",
      " 43  rcaprox   572 non-null    object  \n",
      " 44  rcadist   572 non-null    object  \n",
      "dtypes: Int64(8), category(17), float64(11), object(8), string(1)\n",
      "memory usage: 146.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.dropna(axis=0)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvamos a la selección de atributos momentariamente. Vamos a investigar la correlacion entre los atributos, y eliminar aquellos que tengan una correlación mayor al 35%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 572 entries, 0 to 898\n",
      "Data columns (total 29 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   dataset   572 non-null    string  \n",
      " 1   id        572 non-null    Int64   \n",
      " 2   age       572 non-null    Int64   \n",
      " 3   sex       572 non-null    category\n",
      " 4   painloc   572 non-null    category\n",
      " 5   painexer  572 non-null    category\n",
      " 6   trestbps  572 non-null    float64 \n",
      " 7   htn       572 non-null    object  \n",
      " 8   chol      572 non-null    float64 \n",
      " 9   fbs       572 non-null    category\n",
      " 10  restecg   572 non-null    category\n",
      " 11  ekgmo     572 non-null    Int64   \n",
      " 12  ekgday    572 non-null    Int64   \n",
      " 13  dig       572 non-null    category\n",
      " 14  prop      572 non-null    category\n",
      " 15  nitr      572 non-null    category\n",
      " 16  pro       572 non-null    category\n",
      " 17  diuretic  572 non-null    category\n",
      " 18  thaldur   572 non-null    float64 \n",
      " 19  tpeakbpd  572 non-null    float64 \n",
      " 20  oldpeak   572 non-null    float64 \n",
      " 21  num       572 non-null    category\n",
      " 22  lmt       572 non-null    object  \n",
      " 23  ladprox   572 non-null    object  \n",
      " 24  laddist   572 non-null    object  \n",
      " 25  cxmain    572 non-null    object  \n",
      " 26  om1       572 non-null    object  \n",
      " 27  rcaprox   572 non-null    object  \n",
      " 28  rcadist   572 non-null    object  \n",
      "dtypes: Int64(4), category(11), float64(5), object(8), string(1)\n",
      "memory usage: 94.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "correlation_matrix = dataset.drop(['dataset', 'id', 'num'], axis=1).corr().abs()\n",
    "\n",
    "upper = correlation_matrix.where(\n",
    "    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
    ")\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.35)]\n",
    "\n",
    "dataset = dataset.drop(dataset[to_drop], axis=1)\n",
    "print(dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto tenemos un conjunto de datos completo, procedemos a realizar una optimización de atributos basada en pesos para los atributos. Esto lo hacemos con `SelectFromModel`, utilizando un modelo de regresión logistica para calcular los pesos de los atributos. Esta operacion la preparamos para ser ejecutada dentro de un Pipeline en la etapa de entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_for_selection = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classification', LogisticRegression(max_iter=1000000))\n",
    "])\n",
    "\n",
    "\n",
    "def coef_getter(estimator):\n",
    "    return estimator.named_steps['classification'].coef_\n",
    "\n",
    "selector = SelectFromModel(pipeline_for_selection, threshold='mean', importance_getter=coef_getter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta ultima operación de preprocesamiento, nos quedamos con 18 atributos, mas 2 de metadata, y uno de clase. En total, 21 columnas.\n",
    "\n",
    "## Entrenamiento\n",
    "\n",
    "Ahora que tenemos el dataset preprocesado, procedemos a entrenar el modelo de regresión logistica. Para ello, continuaremos utilizando la libreria `sklearn`. Este paso es similar al utilizado dentro de la optimización de atributos, pero en este caso, utilizaremos validación cruzada en lugar de una división 70-30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset.drop(['num'], axis=1).drop(['dataset', 'id'], axis=1)\n",
    "outputs = dataset['num']\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('selected_features', selector),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classification', LogisticRegression(max_iter=1000000))\n",
    "])\n",
    "\n",
    "output_predictions = cross_val_predict(pipeline, inputs, outputs, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación\n",
    "\n",
    "Finalmente, evaluemos el modelo. Para ello, utilizaremos la libreria `sklearn` nuevamente. En este caso, utilizaremos varias métricas de evaluación, incluyendo la matriz de confusión, la precisión, el recall, y el F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: \n",
      " 0.9920901655485683\n",
      "\n",
      "Confusion Matrix: \n",
      " [[210   1]\n",
      " [  4 357]]\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       211\n",
      "           1       1.00      0.99      0.99       361\n",
      "\n",
      "    accuracy                           0.99       572\n",
      "   macro avg       0.99      0.99      0.99       572\n",
      "weighted avg       0.99      0.99      0.99       572\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('ROC AUC Score: \\n', roc_auc_score(outputs, output_predictions), end='\\n\\n')\n",
    "print('Confusion Matrix: \\n', confusion_matrix(outputs, output_predictions), end='\\n\\n')\n",
    "print('Classification Report: \\n', classification_report(outputs, output_predictions), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con una precisión del 99%, podemos decir que el modelo de regresión logistica es un buen modelo para este dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
